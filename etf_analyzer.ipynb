{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Web Application for an ETF Analyzer\n",
    "\n",
    "In this Challenge assignment, you’ll build a financial database and web application by using SQL, Python, and the Voilà library to analyze the performance of a hypothetical fintech ETF.\n",
    "\n",
    "Instructions: \n",
    "\n",
    "Use this notebook to complete your analysis of a fintech ETF that consists of four stocks: GOST, GS, PYPL, and SQ. Each stock has its own table in the `etf.db` database, which the `Starter_Code` folder also contains.\n",
    "\n",
    "Analyze the daily returns of the ETF stocks both individually and as a whole. Then deploy the visualizations to a web application by using the Voilà library.\n",
    "\n",
    "The detailed instructions are divided into the following parts:\n",
    "\n",
    "* Analyze a single asset in the ETF\n",
    "\n",
    "* Optimize data access with Advanced SQL queries\n",
    "\n",
    "* Analyze the ETF portfolio\n",
    "\n",
    "* Deploy the notebook as a web application\n",
    "\n",
    "#### Analyze a Single Asset in the ETF\n",
    "\n",
    "For this part of the assignment, you’ll use SQL queries with Python, Pandas, and hvPlot to analyze the performance of a single asset from the ETF.\n",
    "\n",
    "Complete the following steps:\n",
    "\n",
    "1. Write a SQL `SELECT` statement by using an f-string that reads all the PYPL data from the database. Using the SQL `SELECT` statement, execute a query that reads the PYPL data from the database into a Pandas DataFrame.\n",
    "\n",
    "2. Use the `head` and `tail` functions to review the first five and the last five rows of the DataFrame. Make a note of the beginning and end dates that are available from this dataset. You’ll use this information to complete your analysis.\n",
    "\n",
    "3. Using hvPlot, create an interactive visualization for the PYPL daily returns. Reflect the “time” column of the DataFrame on the x-axis. Make sure that you professionally style and format your visualization to enhance its readability.\n",
    "\n",
    "4. Using hvPlot, create an interactive visualization for the PYPL cumulative returns. Reflect the “time” column of the DataFrame on the x-axis. Make sure that you professionally style and format your visualization to enhance its readability.\n",
    "\n",
    "#### Optimize Data Access with Advanced SQL Queries\n",
    "\n",
    "For this part of the assignment, you’ll continue to analyze a single asset (PYPL) from the ETF. You’ll use advanced SQL queries to optimize the efficiency of accessing data from the database.\n",
    "\n",
    "Complete the following steps:\n",
    "\n",
    "1. Access the closing prices for PYPL that are greater than 200 by completing the following steps:\n",
    "\n",
    "    - Write a SQL `SELECT` statement to select the dates where the PYPL closing price was higher than 200.0.\n",
    "\n",
    "    - Using the SQL statement, read the data from the database into a Pandas DataFrame, and then review the resulting DataFrame.\n",
    "\n",
    "    - Select the “time” and “close” columns for those dates where the closing price was higher than 200.0.\n",
    "\n",
    "2. Find the top 10 daily returns for PYPL by completing the following steps:\n",
    "\n",
    "    -  Write a SQL statement to find the top 10 PYPL daily returns. Make sure to do the following:\n",
    "\n",
    "        * Use `SELECT` to select only the “time” and “daily_returns” columns.\n",
    "\n",
    "        * Use `ORDER` to sort the results in descending order by the “daily_returns” column.\n",
    "\n",
    "        * Use `LIMIT` to limit the results to the top 10 daily return values.\n",
    "\n",
    "    - Using the SQL statement, read the data from the database into a Pandas DataFrame, and then review the resulting DataFrame.\n",
    "\n",
    "#### Analyze the ETF Portfolio\n",
    "\n",
    "For this part of the assignment, you’ll build the entire ETF portfolio and then evaluate its performance. To do so, you’ll build the ETF portfolio by using SQL joins to combine all the data for each asset.\n",
    "\n",
    "Complete the following steps:\n",
    "\n",
    "1. Write a SQL query to join each table in the portfolio into a single DataFrame. To do so, complete the following steps:\n",
    "\n",
    "    - Use a SQL inner join to join each table on the “time” column. Access the “time” column in the `GDOT` table via the `GDOT.time` syntax. Access the “time” columns from the other tables via similar syntax.\n",
    "\n",
    "    - Using the SQL query, read the data from the database into a Pandas DataFrame. Review the resulting DataFrame.\n",
    "\n",
    "2. Create a DataFrame that averages the “daily_returns” columns for all four assets. Review the resulting DataFrame.\n",
    "\n",
    "    > **Hint** Assuming that this ETF contains equally weighted returns, you can average the returns for each asset to get the average returns of the portfolio. You can then use the average returns of the portfolio to calculate the annualized returns and the cumulative returns. For the calculation to get the average daily returns for the portfolio, use the following code:\n",
    "    >\n",
    "    > ```python\n",
    "    > etf_portfolio_returns = etf_portfolio['daily_returns'].mean(axis=1)\n",
    "    > ```\n",
    "    >\n",
    "    > You can use the average daily returns of the portfolio the same way that you used the daily returns of a single asset.\n",
    "\n",
    "3. Use the average daily returns in the `etf_portfolio_returns` DataFrame to calculate the annualized returns for the portfolio. Display the annualized return value of the ETF portfolio.\n",
    "\n",
    "> **Hint**  To calculate the annualized returns, multiply the mean of the `etf_portfolio_returns` values by 252.\n",
    ">\n",
    "> To convert the decimal values to percentages, multiply the results by 100.\n",
    "\n",
    "4. Use the average daily returns in the `etf_portfolio_returns` DataFrame to calculate the cumulative returns of the ETF portfolio.\n",
    "\n",
    "5. Using hvPlot, create an interactive line plot that visualizes the cumulative return values of the ETF portfolio. Reflect the “time” column of the DataFrame on the x-axis. Make sure that you professionally style and format your visualization to enhance its readability.\n",
    "\n",
    "#### Deploy the Notebook as a Web Application\n",
    "\n",
    "For this part of the assignment, complete the following steps:\n",
    "\n",
    "1. Use the Voilà library to deploy your notebook as a web application. You can deploy the web application locally on your computer.\n",
    "\n",
    "2. Take a screen recording or screenshots to show how the web application appears when using Voilà. Include the recording or screenshots in the `README.md` file for your GitHub repository.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review the following code which imports the required libraries, initiates your SQLite database, popluates the database with records from the `etf.db` seed file that was included in your Starter_Code folder, creates the database engine, and confirms that data tables that it now contains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries and dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import hvplot.pandas\n",
    "import sqlalchemy\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a temporary SQLite database and populate the database with content from the etf.db seed file\n",
    "database_connection_string = 'sqlite:///etf.db'\n",
    "\n",
    "# Create an engine to interact with the SQLite database\n",
    "engine = sqlalchemy.create_engine(database_connection_string)\n",
    "\n",
    "# Confirm that table names contained in the SQLite database.\n",
    "engine.table_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze a single asset in the FinTech ETF\n",
    "\n",
    "For this part of the assignment, you’ll use SQL queries with Python, Pandas, and hvPlot to analyze the performance of a single asset from the ETF.\n",
    "\n",
    "Complete the following steps:\n",
    "\n",
    "1. Write a SQL `SELECT` statement by using an f-string that reads all the PYPL data from the database. Using the SQL `SELECT` statement, execute a query that reads the PYPL data from the database into a Pandas DataFrame.\n",
    "\n",
    "2. Use the `head` and `tail` functions to review the first five and the last five rows of the DataFrame. Make a note of the beginning and end dates that are available from this dataset. You’ll use this information to complete your analysis.\n",
    "\n",
    "3. Using hvPlot, create an interactive visualization for the PYPL daily returns. Reflect the “time” column of the DataFrame on the x-axis. Make sure that you professionally style and format your visualization to enhance its readability.\n",
    "\n",
    "4. Using hvPlot, create an interactive visualization for the PYPL cumulative returns. Reflect the “time” column of the DataFrame on the x-axis. Make sure that you professionally style and format your visualization to enhance its readability.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Write a SQL `SELECT` statement by using an f-string that reads all the PYPL data from the database. Using the SQL `SELECT` statement, execute a query that reads the PYPL data from the database into a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a SQL query to SELECT all of the data from the PYPL table\n",
    "query = f\"\"\"\n",
    "SELECT * FROM pypl\n",
    "\"\"\"\n",
    "\n",
    "# Use the query to read the PYPL data into a Pandas DataFrame\n",
    "pypl_dataframe = pd.read_sql_query(query, engine)\n",
    "\n",
    "# Remvove 0 timestamps from the 'time' column, keep only dates\n",
    "pypl_dataframe['time'] = pd.to_datetime(pypl_dataframe['time'])\n",
    "# Set the index column to 'time'\n",
    "pypl_dataframe = pypl_dataframe.set_index('time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Use the `head` and `tail` functions to review the first five and the last five rows of the DataFrame. Make a note of the beginning and end dates that are available from this dataset. You’ll use this information to complete your analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the first 5 rows of the DataFrame.\n",
    "display(pypl_dataframe.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the last 5 rows of the DataFrame.\n",
    "display(pypl_dataframe.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Using hvPlot, create an interactive visualization for the PYPL daily returns. Reflect the “time” column of the DataFrame on the x-axis. Make sure that you professionally style and format your visualization to enhance its readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an interactive visualization with hvplot to plot the daily returns for PYPL.\n",
    "pypl_dataframe['daily_returns'].hvplot.line(\n",
    "    x = 'time',\n",
    "    xlabel = \"Time\",\n",
    "    y = 'daily_returns',\n",
    "    ylabel = \"Daily Returns\",\n",
    "    title = \"(PYLP) Daily Returns\",\n",
    "    frame_width = 700,\n",
    "    frame_height = 300    \n",
    ").opts(\n",
    "     yformatter='%.04f'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Using hvPlot, create an interactive visualization for the PYPL cumulative returns. Reflect the “time” column of the DataFrame on the x-axis. Make sure that you professionally style and format your visualization to enhance its readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an interactive visaulization with hvplot to plot the cumulative returns for PYPL.\n",
    "\n",
    "#Calculate the cumalitive returns (from the 'daily_returns' column)\n",
    "pypl_dataframe_cum_returns = (1 + pypl_dataframe['daily_returns']).cumprod() - 1\n",
    "\n",
    "# Interactive plot\n",
    "pypl_dataframe_cum_returns.hvplot.line(\n",
    "    xlabel = \"Time\",\n",
    "    ylabel = \"Cumulative Returns\",\n",
    "    title = \"(PYLP) Cumulative Returns\",\n",
    "    frame_width = 700,\n",
    "    frame_height = 300    \n",
    ").opts(\n",
    "     yformatter='%.02f'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize the SQL Queries\n",
    "\n",
    "For this part of the assignment, you’ll continue to analyze a single asset (PYPL) from the ETF. You’ll use advanced SQL queries to optimize the efficiency of accessing data from the database.\n",
    "\n",
    "Complete the following steps:\n",
    "\n",
    "1. Access the closing prices for PYPL that are greater than 200 by completing the following steps:\n",
    "\n",
    "1. Access the closing prices for PYPL that are greater than 200 by completing the following steps:\n",
    "\n",
    "    - Write a SQL `SELECT` statement to select the dates where the PYPL closing price was higher than 200.0.\n",
    "\n",
    "    - Select the “time” and “close” columns for those dates where the closing price was higher than 200.0.\n",
    "\n",
    "    - Using the SQL statement, read the data from the database into a Pandas DataFrame, and then review the resulting DataFrame.\n",
    "\n",
    "2. Find the top 10 daily returns for PYPL by completing the following steps:\n",
    "\n",
    "    -  Write a SQL statement to find the top 10 PYPL daily returns. Make sure to do the following:\n",
    "\n",
    "        * Use `SELECT` to select only the “time” and “daily_returns” columns.\n",
    "\n",
    "        * Use `ORDER` to sort the results in descending order by the “daily_returns” column.\n",
    "\n",
    "        * Use `LIMIT` to limit the results to the top 10 daily return values.\n",
    "\n",
    "    - Using the SQL statement, read the data from the database into a Pandas DataFrame, and then review the resulting DataFrame.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Access the closing prices for PYPL that are greater than 200 by completing the following steps:\n",
    "\n",
    "    - Write a SQL `SELECT` statement to select the dates where the PYPL closing price was higher than 200.0.\n",
    "\n",
    "    - Select the “time” and “close” columns for those dates where the closing price was higher than 200.0.\n",
    "\n",
    "    - Using the SQL statement, read the data from the database into a Pandas DataFrame, and then review the resulting DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Write a SQL SELECT statement to select the time and close columns \n",
    "# where the PYPL closing price was higher than 200.0.\n",
    "query = f\"\"\"\n",
    "SELECT time, close FROM pypl\n",
    "WHERE close > 200.0\n",
    "\"\"\"\n",
    "\n",
    "# Using the query, read the data from the database into a Pandas DataFrame\n",
    "pypl_higher_than_200 =  pd.read_sql_query(query, engine)\n",
    "\n",
    "# Remvove 0 timestamps from the 'time' column, keep only dates\n",
    "pypl_higher_than_200['time'] = pd.to_datetime(pypl_higher_than_200['time'])\n",
    "# Set the index column to 'time'\n",
    "pypl_higher_than_200 = pypl_higher_than_200.set_index('time')\n",
    "\n",
    "# Review the resulting DataFrame\n",
    "display(pypl_higher_than_200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Find the top 10 daily returns for PYPL by completing the following steps:\n",
    "\n",
    "    -  Write a SQL statement to find the top 10 PYPL daily returns. Make sure to do the following:\n",
    "\n",
    "        * Use `SELECT` to select only the “time” and “daily_returns” columns.\n",
    "\n",
    "        * Use `ORDER` to sort the results in descending order by the “daily_returns” column.\n",
    "\n",
    "        * Use `LIMIT` to limit the results to the top 10 daily return values.\n",
    "\n",
    "    - Using the SQL statement, read the data from the database into a Pandas DataFrame, and then review the resulting DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a SQL SELECT statement to select the time and daily_returns columns\n",
    "# Sort the results in descending order and return only the top 10 return values\n",
    "query = f\"\"\"\n",
    "SELECT time, daily_returns FROM pypl\n",
    "ORDER BY daily_returns DESC\n",
    "LIMIT 10 \n",
    "\"\"\"\n",
    "\n",
    "# Using the query, read the data from the database into a Pandas DataFrame\n",
    "pypl_top_10_returns = pd.read_sql_query(query, engine)\n",
    "\n",
    "# Remvove 0 timestamps from the 'time' column, keep only dates\n",
    "pypl_top_10_returns['time'] = pd.to_datetime(pypl_top_10_returns['time'])\n",
    "# Set the index column to 'time'\n",
    "pypl_top_10_returns = pypl_top_10_returns.set_index('time')\n",
    "\n",
    "# Review the resulting DataFrame\n",
    "display(pypl_top_10_returns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze the Fintech ETF Portfolio\n",
    "\n",
    "For this part of the assignment, you’ll build the entire ETF portfolio and then evaluate its performance. To do so, you’ll build the ETF portfolio by using SQL joins to combine all the data for each asset.\n",
    "\n",
    "Complete the following steps:\n",
    "\n",
    "1. Write a SQL query to join each table in the portfolio into a single DataFrame. To do so, complete the following steps:\n",
    "\n",
    "    - Use a SQL inner join to join each table on the “time” column. Access the “time” column in the `GDOT` table via the `GDOT.time` syntax. Access the “time” columns from the other tables via similar syntax.\n",
    "\n",
    "    - Using the SQL query, read the data from the database into a Pandas DataFrame. Review the resulting DataFrame.\n",
    "\n",
    "2. Create a DataFrame that averages the “daily_returns” columns for all four assets. Review the resulting DataFrame.\n",
    "\n",
    "    > **Hint** Assuming that this ETF contains equally weighted returns, you can average the returns for each asset to get the average returns of the portfolio. You can then use the average returns of the portfolio to calculate the annualized returns and the cumulative returns. For the calculation to get the average daily returns for the portfolio, use the following code:\n",
    "    >\n",
    "    > ```python\n",
    "    > etf_portfolio_returns = etf_portfolio['daily_returns'].mean(axis=1)\n",
    "    > ```\n",
    "    >\n",
    "    > You can use the average daily returns of the portfolio the same way that you used the daily returns of a single asset.\n",
    "\n",
    "3. Use the average daily returns in the `etf_portfolio_returns` DataFrame to calculate the annualized returns for the portfolio. Display the annualized return value of the ETF portfolio.\n",
    "\n",
    "> **Hint**  To calculate the annualized returns, multiply the mean of the `etf_portfolio_returns` values by 252.\n",
    ">\n",
    "> To convert the decimal values to percentages, multiply the results by 100.\n",
    "\n",
    "4. Use the average daily returns in the `etf_portfolio_returns` DataFrame to calculate the cumulative returns of the ETF portfolio.\n",
    "\n",
    "5. Using hvPlot, create an interactive line plot that visualizes the cumulative return values of the ETF portfolio. Reflect the “time” column of the DataFrame on the x-axis. Make sure that you professionally style and format your visualization to enhance its readability.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Write a SQL query to join each table in the portfolio into a single DataFrame. To do so, complete the following steps:\n",
    "\n",
    "    - Use a SQL inner join to join each table on the “time” column. Access the “time” column in the `GDOT` table via the `GDOT.time` syntax. Access the “time” columns from the other tables via similar syntax.\n",
    "\n",
    "    - Using the SQL query, read the data from the database into a Pandas DataFrame. Review the resulting DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# First, lets review all the individual asset dataframes...\n",
    "\n",
    "query = f\"\"\"\n",
    "SELECT * FROM gdot\n",
    "\"\"\"\n",
    "GDOT_dataframe = pd.read_sql_query(query, engine)\n",
    "display(GDOT_dataframe.tail())\n",
    "\n",
    "query = f\"\"\"\n",
    "SELECT * FROM gs\n",
    "\"\"\"\n",
    "GS_dataframe = pd.read_sql_query(query, engine)\n",
    "display(GS_dataframe.tail())\n",
    "\n",
    "query = f\"\"\"\n",
    "SELECT * FROM pypl\n",
    "\"\"\"\n",
    "PYPL_dataframe = pd.read_sql_query(query, engine)\n",
    "display(PYPL_dataframe.tail())\n",
    "\n",
    "query = f\"\"\"\n",
    "SELECT * FROM sq\n",
    "\"\"\"\n",
    "SQ_dataframe = pd.read_sql_query(query, engine)\n",
    "display(SQ_dataframe.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Method #1: Select all columns from each asset\n",
    "\n",
    "# Wreate a SQL query to join each table in the portfolio into a single DataFrame \n",
    "# Use the time column from each table as the basis for the join\n",
    "query = f\"\"\"\n",
    "SELECT * FROM gdot\n",
    "INNER JOIN gs   ON gdot.time = gs.time\n",
    "INNER JOIN pypl ON gdot.time = pypl.time\n",
    "INNER JOIN sq   ON gdot.time = sq.time    \n",
    "\"\"\"\n",
    "\n",
    "# Using the query, read the data from the database into a Pandas DataFrame\n",
    "etf_portfolio = pd.read_sql_query(query, engine)\n",
    "\n",
    "# Remove redundant time columns\n",
    "etf_portfolio = etf_portfolio.T.drop_duplicates().T\n",
    "\n",
    "# Remvove 0 timestamps from the 'time' column, keep only dates\n",
    "etf_portfolio['time'] = pd.to_datetime(etf_portfolio['time'])\n",
    "# Set the index column to 'time'\n",
    "etf_portfolio = etf_portfolio.set_index('time')\n",
    "\n",
    "# Since each of the portfolios have the same column names (open, high, close, etc.), renaming the columns prepending asset names\n",
    "etf_portfolio.columns = ['GDOT.open', 'GDOT.high', 'GDOT.low', 'GDOT.close', 'GDOT.volume', 'GDOT.daily_returns',\n",
    "                         'GS.open',   'GS.high',   'GS.low',   'GS.close',   'GS.volume',   'GS.daily_returns',\n",
    "                         'PYPL.open', 'PYPL.high', 'PYPL.low', 'PYPL.close', 'PYPL.volume', 'PYPL.daily_returns',\n",
    "                         'SQ.open',   'SQ.high',   'SQ.low',   'SQ.close',   'SQ.volume',   'SQ.daily_returns']\n",
    "\n",
    "# Review the resulting DataFrame\n",
    "display(etf_portfolio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Method #2: Filter out time from only one of the portfolios, and select which columns from each asset to extract\n",
    "\n",
    "# Wreate a SQL query to join each table in the portfolio into a single DataFrame \n",
    "# Use the time column from each table as the basis for the join\n",
    "query = f\"\"\"\n",
    "SELECT \n",
    "    gdot.time, gdot.open, gdot.high, gdot.low, gdot.close, gdot.volume, gdot.daily_returns,\n",
    "               gs.open,   gs.high,   gs.low,   gs.close,   gs.volume,   gs.daily_returns,\n",
    "               pypl.open, pypl.high, pypl.low, pypl.close, pypl.volume, pypl.daily_returns,\n",
    "               sq.open,   sq.high,   gdot.low, sq.close,   sq.volume,   sq.daily_returns\n",
    "FROM gdot\n",
    "INNER JOIN gs   ON gdot.time = gs.time\n",
    "INNER JOIN pypl ON gdot.time = pypl.time\n",
    "INNER JOIN sq   ON gdot.time = sq.time    \n",
    "\"\"\"\n",
    "\n",
    "# Using the query, read the data from the database into a Pandas DataFrame\n",
    "etf_portfolio = pd.read_sql_query(query, engine)\n",
    "\n",
    "# Remvove 0 timestamps from the 'time' column, keep only dates\n",
    "etf_portfolio['time'] = pd.to_datetime(etf_portfolio['time'])\n",
    "# Set the index column to 'time'\n",
    "etf_portfolio = etf_portfolio.set_index('time')\n",
    "\n",
    "# Since each of the portfolios have the same column names (open, high, close, etc.), renaming the columns\n",
    "# prepending the portfolio names.\n",
    "etf_portfolio.columns = ['GDOT.open', 'GDOT.high', 'GDOT.low', 'GDOT.close', 'GDOT.volume', 'GDOT.daily_returns',\n",
    "                         'GS.open',   'GS.high',   'GS.low',   'GS.close',   'GS.volume',   'GS.daily_returns',\n",
    "                         'PYPL.open', 'PYPL.high', 'PYPL.low', 'PYPL.close', 'PYPL.volume', 'PYPL.daily_returns',\n",
    "                         'SQ.open',   'SQ.high',   'SQ.low',   'SQ.close',   'SQ.volume',   'SQ.daily_returns']\n",
    "\n",
    "display(etf_portfolio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Create a DataFrame that averages the “daily_returns” columns for all four assets. Review the resulting DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a DataFrame that displays the mean value of the “daily_returns” columns for all four assets.\n",
    "\n",
    "# Method #1 Filter via dataframe (for demonstration purposes only)\n",
    "# Create a data frame with the daily returns from all 4 portfolios\n",
    "etf_portfolio_returns_df = etf_portfolio[['GDOT.daily_returns', 'GS.daily_returns', 'PYPL.daily_returns', 'SQ.daily_returns']]\n",
    "\n",
    "# Method #2 : Filter via SQL\n",
    "query = f\"\"\"\n",
    "SELECT \n",
    "    gdot.time, gdot.daily_returns,\n",
    "               gs.daily_returns,\n",
    "               pypl.daily_returns,\n",
    "               sq.daily_returns\n",
    "FROM gdot\n",
    "INNER JOIN gs   ON gdot.time = gs.time\n",
    "INNER JOIN pypl ON gdot.time = pypl.time\n",
    "INNER JOIN sq   ON gdot.time = sq.time    \n",
    "\"\"\"\n",
    "# Using the query, read the data from the database into a Pandas DataFrame\n",
    "etf_portfolio_returns_sql = pd.read_sql_query(query, engine)\n",
    "# Remvove 0 timestamps from the 'time' column, keep only dates\n",
    "etf_portfolio_returns_sql['time'] = pd.to_datetime(etf_portfolio_returns_sql['time'])\n",
    "# Set the index column to 'time'\n",
    "etf_portfolio_returns_sql = etf_portfolio_returns_sql.set_index('time')\n",
    "\n",
    "# Choose method #2 (SQL) approach (preferred to filter via SQL)\n",
    "etf_portfolio_returns = etf_portfolio_returns_sql\n",
    "\n",
    "# Since each of the portfolios have the same column names (daily returns), renaming the columns prepending the asset names.\n",
    "etf_portfolio_returns.columns = ['GDOT.daily_returns', 'GS.daily_returns', 'PYPL.daily_returns', 'SQ.daily_returns']\n",
    "\n",
    "# Add a column to the etf portfolio dataframe to include the annualized mean daily returns\n",
    "etf_portfolio_returns['ETF.mean_daily_returns'] = etf_portfolio_returns.mean(axis=1)\n",
    "\n",
    "# Review the resulting DataFrame\n",
    "display(etf_portfolio_returns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Use the average daily returns in the etf_portfolio_returns DataFrame to calculate the annualized returns for the portfolio. Display the annualized return value of the ETF portfolio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the average daily returns provided by the etf_portfolio_returns DataFrame \n",
    "# to calculate the annualized return for the portfolio. \n",
    "annualized_etf_portfolio_returns = etf_portfolio_returns['ETF.mean_daily_returns'] * 252\n",
    "\n",
    "# Display the annualized return value of the ETF portfolio.\n",
    "display(annualized_etf_portfolio_returns)\n",
    "\n",
    "# Add a column to the etf portfolio dataframe to include the annualized mean daily returns\n",
    "etf_portfolio_returns['ETF.ann_mean_daily_returns'] = annualized_etf_portfolio_returns\n",
    "display(etf_portfolio_returns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Use the average daily returns in the `etf_portfolio_returns` DataFrame to calculate the cumulative returns of the ETF portfolio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the average daily returns provided by the etf_portfolio_returns DataFrame \n",
    "# to calculate the cumulative returns\n",
    "etf_cumulative_returns = (1 + etf_portfolio_returns['ETF.mean_daily_returns']).cumprod() - 1\n",
    "\n",
    "# Display the final cumulative return value\n",
    "display(etf_cumulative_returns)\n",
    "\n",
    "# Add a column to the etf portfolio dataframe to include the cumulative returns\n",
    "etf_portfolio_returns['ETF.cum_returns'] = etf_cumulative_returns\n",
    "display(etf_portfolio_returns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Using hvPlot, create an interactive line plot that visualizes the cumulative return values of the ETF portfolio. Reflect the “time” column of the DataFrame on the x-axis. Make sure that you professionally style and format your visualization to enhance its readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an interactive visualization with hvplot to plot the daily returns for PYPL.\n",
    "etf_portfolio_returns.hvplot.line(\n",
    "    x = \"time\",\n",
    "    xlabel = \"Time\",\n",
    "    y = \"PYPL.daily_returns\",\n",
    "    ylabel = \"Cumulative Returns\",\n",
    "    title = \"(PYPL) Daily Returns\",\n",
    "    frame_width = 700,\n",
    "    frame_height = 300    \n",
    ").opts(\n",
    "     yformatter='%.02f'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an interactive visaulization with hvplot to plot the cumulative returns for PYPL.\n",
    "\n",
    "etf_cumulative_return_ppyls = (1 + etf_portfolio_returns['PYPL.daily_returns']).cumprod() - 1\n",
    "\n",
    "etf_cumulative_return_ppyls.hvplot.line(\n",
    "    xlabel = \"Time\",\n",
    "    ylabel = \"Cumulative Returns\",\n",
    "    title = \"(PYPL) Cumulative Returns\",\n",
    "    frame_width = 700,\n",
    "    frame_height = 300    \n",
    ").opts(\n",
    "     yformatter='%.02f'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using hvplot, create an interactive line plot that visualizes the ETF portfolios cumulative return values.\n",
    "etf_portfolio_returns.hvplot.line(\n",
    "    x = \"time\",\n",
    "    xlabel = \"Time\",\n",
    "    y = \"ETF.cum_returns\",\n",
    "    ylabel = \"Cumulative Returns\",\n",
    "    title = \"ETF (GDOT, GS, PYPL, SQ) Cumulative Returns\",\n",
    "    frame_width = 700,\n",
    "    frame_height = 300    \n",
    ").opts(\n",
    "     yformatter='%.02f'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
